{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "union-alcohol",
   "metadata": {},
   "source": [
    "# Activity 1.2 : Training Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-teens",
   "metadata": {},
   "source": [
    "#### Objective(s):\n",
    "\n",
    "This activity aims to demonstrate how to train neural networks using keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-modem",
   "metadata": {},
   "source": [
    "#### Intended Learning Outcomes (ILOs):\n",
    "* Demonstrate how to build and train neural networks \n",
    "* Demonstrate how to evaluate and plot the model using training and validation loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-april",
   "metadata": {},
   "source": [
    "#### Resources:\n",
    "* Jupyter Notebook\n",
    "\n",
    "CI Pima Diabetes Dataset\n",
    "\n",
    "* pima-indians-diabetes.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-fountain",
   "metadata": {},
   "source": [
    "#### Procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-therapist",
   "metadata": {},
   "source": [
    "Load the necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-newsletter",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filepath = \"pima-indians-diabetes.csv\"\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv(filepath, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-carnival",
   "metadata": {},
   "source": [
    "Check the top 5 samples of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-lafayette",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-parallel",
   "metadata": {},
   "source": [
    "Split the data to Train, and Test (75%, 25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-reconstruction",
   "metadata": {},
   "source": [
    "Build a single hidden layer neural network using 12 nodes. \n",
    "Use the sequential model with single layer network and input shape to 8. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-zealand",
   "metadata": {},
   "source": [
    "Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-electricity",
   "metadata": {},
   "source": [
    "Define the model:\n",
    "* Input size is 8-dimensional\n",
    "* 1 hidden layer, 12 hidden nodes, sigmoid activation \n",
    "* Final layer with one node and sigmoid activation (standard for binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model  = Sequential([\n",
    "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-terminal",
   "metadata": {},
   "source": [
    "View the model summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-anderson",
   "metadata": {},
   "source": [
    "Train the model \n",
    "* Compile the model with optimizer, loss function and metrics\n",
    "* Use the fit function to return the run history. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model.predict(X_test_norm)\n",
    "y_pred_prob_nn_1 = model.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa5caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-estonia",
   "metadata": {},
   "source": [
    "Create the plot_roc function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-festival",
   "metadata": {},
   "source": [
    "Evaluate the model performance and plot the ROC CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,np.round(y_pred_class_nn_1))))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-nevada",
   "metadata": {},
   "source": [
    " Plot the training loss and the validation loss over the different epochs and see how it looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-circus",
   "metadata": {},
   "source": [
    "What is your interpretation about the result of the train and validation loss?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-cherry",
   "metadata": {},
   "source": [
    "The training and validation loss both decrease steadily over time, indicating that the model is learning meaningful patterns from the data. The validation loss remains slightly higher than the training loss, which suggests mild overfitting, but the gap is small and stable, indicating that the model still generalizes reasonably well to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-slovak",
   "metadata": {},
   "source": [
    "#### Supplementary Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-publisher",
   "metadata": {},
   "source": [
    "* Build a model with two hidden layers, each with 6 nodes\n",
    "* Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "* Use a learning rate of .003 and train for 1500 epochs\n",
    "* Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "* Plot the roc curve for the predictions\n",
    "* Use different learning rates, numbers of epochs, and network structures. \n",
    "* Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
    "* Interpret your result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d5ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================\n",
    "# Utilities\n",
    "# =============================\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_grad(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def logloss(y_true, y_pred, eps=1e-12):\n",
    "    y_pred = np.clip(y_pred, eps, 1-eps)\n",
    "    return -np.mean(y_true*np.log(y_pred) + (1-y_true)*np.log(1-y_pred))\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean((y_pred >= 0.5) == (y_true == 1))\n",
    "\n",
    "def train_test_split(X, y, test_size=0.25, seed=1241):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(len(X))\n",
    "    rng.shuffle(idx)\n",
    "    cut = int(len(X) * (1 - test_size))\n",
    "    tr, te = idx[:cut], idx[cut:]\n",
    "    return X[tr], X[te], y[tr], y[te]\n",
    "\n",
    "# =============================\n",
    "# ROC (manual)\n",
    "# =============================\n",
    "def roc_curve_manual(y_true, y_score, num_thresh=200):\n",
    "    thresholds = np.linspace(1, 0, num_thresh)\n",
    "    tpr_list, fpr_list = [], []\n",
    "    P = np.sum(y_true == 1)\n",
    "    N = np.sum(y_true == 0)\n",
    "    for t in thresholds:\n",
    "        y_hat = (y_score >= t)\n",
    "        TP = np.sum((y_hat == 1) & (y_true == 1))\n",
    "        FP = np.sum((y_hat == 1) & (y_true == 0))\n",
    "        tpr = TP / P if P else 0.0\n",
    "        fpr = FP / N if N else 0.0\n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "    return np.array(fpr_list), np.array(tpr_list)\n",
    "\n",
    "def auc_trapz(x, y):\n",
    "    order = np.argsort(x)\n",
    "    return np.trapz(y[order], x[order])\n",
    "\n",
    "# =============================\n",
    "# 2-hidden-layer MLP\n",
    "# =============================\n",
    "def init_params(input_dim, h1, h2, seed=1241):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    W1 = rng.normal(0, np.sqrt(2/input_dim), size=(input_dim, h1))\n",
    "    b1 = np.zeros((1, h1))\n",
    "    W2 = rng.normal(0, np.sqrt(2/h1), size=(h1, h2))\n",
    "    b2 = np.zeros((1, h2))\n",
    "    W3 = rng.normal(0, np.sqrt(1/h2), size=(h2, 1))\n",
    "    b3 = np.zeros((1, 1))\n",
    "    return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "def forward(X, W1, b1, W2, b2, W3, b3):\n",
    "    Z1 = X @ W1 + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = A1 @ W2 + b2\n",
    "    A2 = relu(Z2)\n",
    "    Z3 = A2 @ W3 + b3\n",
    "    Yhat = sigmoid(Z3)\n",
    "    cache = (X, Z1, A1, Z2, A2, Z3, Yhat)\n",
    "    return Yhat, cache\n",
    "\n",
    "def backward(y, cache, W2, W3):\n",
    "    X, Z1, A1, Z2, A2, Z3, Yhat = cache\n",
    "    N = X.shape[0]\n",
    "    y = y.reshape(-1,1)\n",
    "\n",
    "    dZ3 = (Yhat - y) / N\n",
    "    dW3 = A2.T @ dZ3\n",
    "    db3 = np.sum(dZ3, axis=0, keepdims=True)\n",
    "\n",
    "    dA2 = dZ3 @ W3.T\n",
    "    dZ2 = dA2 * relu_grad(Z2)\n",
    "    dW2 = A1.T @ dZ2\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
    "\n",
    "    dA1 = dZ2 @ W2.T\n",
    "    dZ1 = dA1 * relu_grad(Z1)\n",
    "    dW1 = X.T @ dZ1\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
    "\n",
    "    return dW1, db1, dW2, db2, dW3, db3\n",
    "\n",
    "def fit_mlp(X_train, y_train, X_test, y_test,\n",
    "            h1=6, h2=6, lr=0.003, epochs=1500,\n",
    "            seed=1241, print_every=300):\n",
    "\n",
    "    W1,b1,W2,b2,W3,b3 = init_params(X_train.shape[1], h1, h2, seed)\n",
    "\n",
    "    tr_loss, te_loss = [], []\n",
    "    tr_acc, te_acc = [], []\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        yhat_tr, cache = forward(X_train, W1,b1,W2,b2,W3,b3)\n",
    "\n",
    "        yhat_tr_flat = yhat_tr.reshape(-1)\n",
    "        L_tr = logloss(y_train, yhat_tr_flat)\n",
    "        A_tr = accuracy(y_train, yhat_tr_flat)\n",
    "\n",
    "        dW1,db1,dW2,db2,dW3,db3 = backward(y_train, cache, W2, W3)\n",
    "\n",
    "        W1 -= lr*dW1; b1 -= lr*db1\n",
    "        W2 -= lr*dW2; b2 -= lr*db2\n",
    "        W3 -= lr*dW3; b3 -= lr*db3\n",
    "\n",
    "        yhat_te, _ = forward(X_test, W1,b1,W2,b2,W3,b3)\n",
    "        yhat_te_flat = yhat_te.reshape(-1)\n",
    "\n",
    "        L_te = logloss(y_test, yhat_te_flat)\n",
    "        A_te = accuracy(y_test, yhat_te_flat)\n",
    "\n",
    "        tr_loss.append(L_tr); te_loss.append(L_te)\n",
    "        tr_acc.append(A_tr); te_acc.append(A_te)\n",
    "\n",
    "        if ep % print_every == 0 or ep == 1:\n",
    "            print(f\"epoch {ep} | train loss {L_tr:.4f} acc {A_tr:.4f} | \"\n",
    "                  f\"val loss {L_te:.4f} acc {A_te:.4f}\")\n",
    "\n",
    "    return (W1,b1,W2,b2,W3,b3), {\n",
    "        \"train_loss\": np.array(tr_loss),\n",
    "        \"val_loss\": np.array(te_loss),\n",
    "        \"train_acc\": np.array(tr_acc),\n",
    "        \"val_acc\": np.array(te_acc),\n",
    "    }\n",
    "\n",
    "def predict_proba(X, params):\n",
    "    W1,b1,W2,b2,W3,b3 = params\n",
    "    yhat, _ = forward(X, W1,b1,W2,b2,W3,b3)\n",
    "    return yhat.reshape(-1)\n",
    "\n",
    "# =============================\n",
    "# DATA (assumes x_mat_full, y already exist)\n",
    "# =============================\n",
    "X = x_mat_full\n",
    "y_vec = y.reshape(-1).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_vec)\n",
    "\n",
    "# =============================\n",
    "# BASE MODEL\n",
    "# =============================\n",
    "params, hist = fit_mlp(\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    h1=6, h2=6, lr=0.003, epochs=1500\n",
    ")\n",
    "\n",
    "# Loss plot\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(hist[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(hist[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend(); plt.grid(); plt.title(\"Loss\"); plt.show()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(hist[\"train_acc\"], label=\"Train Accuracy\")\n",
    "plt.plot(hist[\"val_acc\"], label=\"Validation Accuracy\")\n",
    "plt.legend(); plt.grid(); plt.title(\"Accuracy\"); plt.show()\n",
    "\n",
    "# =============================\n",
    "# ROC\n",
    "# =============================\n",
    "y_score = predict_proba(X_test, params)\n",
    "fpr, tpr = roc_curve_manual(y_test, y_score)\n",
    "auc = auc_trapz(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(fpr, tpr, label=f\"AUC={auc:.3f}\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.legend(); plt.grid()\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\"); plt.show()\n",
    "\n",
    "# =============================\n",
    "# EXPERIMENTS\n",
    "# =============================\n",
    "experiments = [\n",
    "    (0.001, 1500, 6, 6),\n",
    "    (0.003, 1500, 6, 6),\n",
    "    (0.01, 1500, 6, 6),\n",
    "    (0.003, 1500, 4, 4),\n",
    "    (0.003, 1500, 8, 8),\n",
    "    (0.003, 800, 6, 6)\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "for lr, ep, h1, h2 in experiments:\n",
    "    _, h = fit_mlp(X_train, y_train, X_test, y_test,\n",
    "                   h1=h1, h2=h2, lr=lr, epochs=ep,\n",
    "                   print_every=999999)\n",
    "    plt.plot(h[\"val_loss\"], label=f\"lr={lr}, ({h1},{h2}), ep={ep}\")\n",
    "\n",
    "plt.legend(); plt.grid()\n",
    "plt.title(\"Validation Loss Comparison\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-factory",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-appointment",
   "metadata": {},
   "source": [
    "This activity demonstrated how to build and train neural networks and how to evaluate model performance using training and validation loss plots. However, the Keras-based model could not be fully executed on my home desktop due to persistent environment and dependency issues, and I was unable to debug and resolve the problem despite external assistance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630d4c6e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
